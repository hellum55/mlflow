{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Classification Recipe Notebook\n",
    "\n",
    "This notebook runs the MLflow Classification Recipe on Databricks and inspects its results. For more information about the MLflow Classification Recipe, including usage examples, see the [Classification Recipe overview documentation](https://mlflow.org/docs/latest/recipes.html#classification-recipe) the [Classification Recipe API documentation](https://mlflow.org/docs/latest/python_api/mlflow.recipes.html#module-mlflow.recipes.classification.v1.recipe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.recipes import Recipe\n",
    "\n",
    "r = Recipe(profile=\"local\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.inspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"ingest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.run(\"register\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.inspect(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = r.get_artifact(\"training_data\")\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    TrainingArguments,\n",
    ")        \n",
    "\n",
    "def trainer_fn(estimator_params: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Returns an *untrained* HF trainer here.\n",
    "\n",
    "    Input estimator_params is a dictionary of parameters passed to the estimator.\n",
    "    It contains the following keys:\n",
    "      'train_dataset': A ``datasets.Dataset`` object for training.\n",
    "      'cache_dir': A string containing the path to the cache directory.\n",
    "    \"\"\"\n",
    "    training_args = TrainingArguments(output_dir=estimator_params[\"cache_dir\"])\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=training_args.output_dir,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=training_args.output_dir,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        config=config,\n",
    "        cache_dir=training_args.output_dir,\n",
    "    )\n",
    "    # We resize the embeddings only when necessary to avoid index errors. If you are creating a model from scratch\n",
    "    # on a small vocab and want a smaller embedding size, remove this test.\n",
    "    embedding_size = model.get_input_embeddings().weight.shape[0]\n",
    "    if len(tokenizer) > embedding_size:\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    def preprocess_squad_batch(\n",
    "        examples,\n",
    "        question_column: str,\n",
    "        answer_column: str,\n",
    "    ) -> Tuple[List[str], List[str]]:\n",
    "        questions = examples[question_column]\n",
    "        answers = examples[answer_column]\n",
    "        return questions, answers\n",
    "\n",
    "    def preprocess_examples(examples):\n",
    "        question_column = \"character\"\n",
    "        answer_column = \"speech\"\n",
    "        inputs, targets = preprocess_squad_batch(\n",
    "            examples, question_column, answer_column\n",
    "        )\n",
    "        model_inputs = tokenizer(\n",
    "            inputs,\n",
    "            targets,\n",
    "            max_length=384,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        return model_inputs\n",
    "\n",
    "    train_dataset = estimator_params[\"train_dataset\"]\n",
    "    # Create train feature from dataset\n",
    "    train_dataset = train_dataset.map(\n",
    "        preprocess_examples,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "    )\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=tokenizer.pad_token_id,\n",
    "        pad_to_multiple_of=8,\n",
    "    )\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(training_data)\n",
    "cache_dir = \"./\"\n",
    "trainer = trainer_fn(estimator_params={\"train_dataset\": train_dataset, \"cache_dir\": cache_dir})\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-dev",
   "language": "python",
   "name": "mlflow-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3005fbe2ecd09dea1d4dca11a7a43ec8253760cbaeb4d6f5c370cc1f02496db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
